# -*- coding: utf-8 -*-
"""USA House Price Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xVsAu5IBcvAKtuYciHBBV-cRl-YUBOxQ
"""

import pandas as pd
import numpy as np
housing = pd.read_csv("/content/Housing[1].csv")
housing.head()

housing.shape

housing.info()

housing.describe()

"""2.Visualizing the Data"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.pairplot(housing)
plt.show()

plt.figure(figsize=(20,12)) # figsize is a parameter within plt.figure()
plt.subplot(2,3,1)
sns.boxplot(x = 'mainroad', y = 'price', data = housing) # Removed quotes around housing
plt.subplot(2,3,2)
sns.boxplot(x = 'guestroom', y = 'price', data = housing) # Removed quotes around housing
plt.subplot(2,3,3)
sns.boxplot(x = 'basement', y = 'price', data = housing) # Removed quotes around housing
plt.subplot(2,3,4)
sns.boxplot(x = 'hotwaterheating', y = 'price', data = housing) # Removed quotes around housing
plt.subplot(2,3,5)
sns.boxplot(x = 'airconditioning', y = 'price', data = housing) # Removed quotes around housing
plt.subplot(2,3,6)
sns.boxplot(x = 'furnishingstatus', y = 'price', data = housing) # Removed quotes around housing
plt.show()

plt.figure(figsize=(10,5))
sns.boxplot(x ='furnishingstatus', y = 'price', hue ='airconditioning', data = housing) # Pass the DataFrame 'housing'
plt.show()

"""3.Data Preparation

"""

#list of variables to map
varlist =['mainroad','guestroom','basement','hotwaterheating','airconditioning','prefarea']
housing[varlist] = housing[varlist].apply(lambda x: x.map({'yes':1,'no':0}))
#check the housing dataframe now
housing.head() # Use 'housing' instead of 'house'

status = pd.get_dummies(housing['furnishingstatus'])
status.head()

status = pd.get_dummies(housing['furnishingstatus'], drop_first = True)
housing = pd.concat([housing, status], axis = 1)
housing.head()

housing.drop(['furnishingstatus'], axis = 1, inplace = True)
housing.head()

"""4.Spliting the dataset into training and testing sets

"""

from sklearn.model_selection import train_test_split
np.random.seed(0)
df_train, df_test = train_test_split(housing, train_size = 0.7, test_size = 0.3, random_state = 100)
#

"""Rescalling the features"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_train.head()

num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price']
df_train[num_vars] = scaler.fit_transform(df_train[num_vars])
df_train.head()

#lets check the coeffitient correlation
plt.figure(figsize=(16,10)) # figsize is now defined from plt
sns.heatmap(df_train.corr(), annot = True, cmap = "YlGnBu") # Correct the colormap name
plt.show() # Call the show function

plt.figure(figsize=(6,6)) # Call the figsize argument within the figure function
plt.scatter(df_train['area'], df_train['price'])
plt.show()

y_train = df_train.pop('price')
X_train = df_train

"""5.Building a linear model"""

import statsmodels.api as sm


# Convert all columns in X_train to numeric if possible, coercing errors
X_train_numeric = X_train.apply(pd.to_numeric, errors='coerce')

# Add a constant to the numeric feature matrix
X_train_lm = sm.add_constant(X_train[['area']])

#create a first fitted model
lr = sm.OLS(y_train, X_train_lm).fit()
lr.params

print(lr.summary())

X_train_lm = X_train[['area','bathrooms','bedrooms']] # Capitalize x_train to X_train

import statsmodels.api as sm

X_train_lm = sm.add_constant(X_train_lm)

lr = sm.OLS(y_train, X_train_lm).fit()

lr.params

print(lr.summary())

housing.columns

import statsmodels.api as sm
import pandas as pd


# Add a constant to the model
x_train_lm = sm.add_constant(X_train_numeric)

# Fit the model
lr_l = sm.OLS(y_train, X_train_lm).fit()

# Print parameters
print(lr_l.params)

print(lr_l.summary())

#check for the VIF values of thefeature variables
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Import the pandas library
import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Replace ... with your actual numerical data
# Example:
X_train_numeric_data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
X_train_numeric = pd.DataFrame(X_train_numeric_data, columns=['feature1', 'feature2', 'feature3'])

# Calculate VIF
vif_df = pd.DataFrame() # Changed variable name to avoid overwriting the function
vif_df['Features'] = X_train_numeric.columns
vif_df['VIF'] = [variance_inflation_factor(X_train_numeric.values, i) for i in range(X_train_numeric.shape[1])]
vif_df['VIF'] = round(vif_df['VIF'],2)
vif_df = vif_df.sort_values(by = "VIF", ascending = False)
vif_df

"""Dropping the values and updating the model"""

# Import the pandas library (if not already done)
import pandas as pd

# Create a sample DataFrame (replace with your actual data)
data = {'bedrooms': [2, 3, 4], 'bathrooms': [1, 2, 2], 'price': [200000, 300000, 450000]}
df = pd.DataFrame(data)

# Now you can drop the 'bedrooms' column
df = df.drop('bedrooms', axis=1)

print(df)

# Import the statsmodels library with the 'sm' alias
import statsmodels.api as sm

# Assuming 'X_train_numeric' from your previous code is what you intend to use
x = X_train_numeric

#build a second fitted model
X_train_lm = sm.add_constant(x)

# Create a sample y_train (replace this with your actual target variable data)
y_train = [10, 20, 30]  # Example target variable data

lr_3 = sm.OLS(y_train, X_train_lm).fit()

print(lr_3.summary()) # Print a summary of the regression results

#importing RFE and linearregression
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

#importing RFE and linearregression
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

# Create sample data for x_train (replace with your actual data)
x_train = [[1, 2], [3, 4], [5, 6]]  # Example feature data

#running rfe with the output number of the variables equal to 10
lm = LinearRegression()

lm.fit(x_train,y_train)
rfe = RFE(lm, n_features_to_select=10) # Use named argument for clarity
rfe = rfe.fit(x_train, y_train)

list(zip,x_train.columns,rfe.support_,rfe.ranking))